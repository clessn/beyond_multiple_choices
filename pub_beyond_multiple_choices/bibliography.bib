@misc{abdin_etal24,
  title = {Phi-3 {{Technical Report}}: {{A Highly Capable Language Model Locally}} on {{Your Phone}}},
  shorttitle = {Phi-3 {{Technical Report}}},
  author = {Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and Benhaim, Alon and Bilenko, Misha and Bjorck, Johan and Bubeck, S{\'e}bastien and Cai, Qin and Cai, Martin and Mendes, Caio C{\'e}sar Teodoro and Chen, Weizhu and Chaudhary, Vishrav and Chen, Dong and Chen, Dongdong and Chen, Yen-Chun and Chen, Yi-Ling and Chopra, Parul and Dai, Xiyang and Del Giorno, Allie and {de Rosa}, Gustavo and Dixon, Matthew and Eldan, Ronen and Fragoso, Victor and Iter, Dan and Gao, Mei and Gao, Min and Gao, Jianfeng and Garg, Amit and Goswami, Abhishek and Gunasekar, Suriya and Haider, Emman and Hao, Junheng and Hewett, Russell J. and Huynh, Jamie and Javaheripi, Mojan and Jin, Xin and Kauffmann, Piero and Karampatziakis, Nikos and Kim, Dongwoo and Khademi, Mahoud and Kurilenko, Lev and Lee, James R. and Lee, Yin Tat and Li, Yuanzhi and Li, Yunsheng and Liang, Chen and Liden, Lars and Liu, Ce and Liu, Mengchen and Liu, Weishung and Lin, Eric and Lin, Zeqi and Luo, Chong and Madan, Piyush and Mazzola, Matt and Mitra, Arindam and Modi, Hardik and Nguyen, Anh and Norick, Brandon and Patra, Barun and {Perez-Becker}, Daniel and Portet, Thomas and Pryzant, Reid and Qin, Heyang and Radmilac, Marko and Rosset, Corby and Roy, Sambudha and Ruwase, Olatunji and Saarikivi, Olli and Saied, Amin and Salim, Adil and Santacroce, Michael and Shah, Shital and Shang, Ning and Sharma, Hiteshi and Shukla, Swadheen and Song, Xia and Tanaka, Masahiro and Tupini, Andrea and Wang, Xin and Wang, Lijuan and Wang, Chunyu and Wang, Yu and Ward, Rachel and Wang, Guanhua and Witte, Philipp and Wu, Haiping and Wyatt, Michael and Xiao, Bin and Xu, Can and Xu, Jiahang and Xu, Weijian and Yadav, Sonali and Yang, Fan and Yang, Jianwei and Yang, Ziyi and Yang, Yifan and Yu, Donghan and Yuan, Lu and Zhang, Chengruidong and Zhang, Cyril and Zhang, Jianwen and Zhang, Li Lyna and Zhang, Yi and Zhang, Yue and Zhang, Yunan and Zhou, Xiren},
  year = {2024},
  month = may,
  number = {arXiv:2404.14219},
  eprint = {2404.14219},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.14219},
  urldate = {2024-06-05},
  abstract = {We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69\% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered publicly available web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75\% and 78\% on MMLU, and 8.7 and 8.9 on MT-bench). Moreover, we also introduce phi-3-vision, a 4.2 billion parameter model based on phi-3-mini with strong reasoning capabilities for image and text prompts.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/K5TL8ZKQ/Abdin et al_2024_Phi-3 Technical Report.pdf;/home/ral/Zotero/storage/ATC7BYU6/2404.html}
}

@book{bickman_rog09,
  title = {The {{SAGE}} Handbook of Applied Social Research Methods},
  editor = {Bickman, Leonard and Rog, Debra J.},
  year = {2009},
  edition = {2nd ed},
  publisher = {SAGE},
  address = {Los Angeles},
  isbn = {978-1-4129-5031-2},
  langid = {english},
  lccn = {H62 .H24534 2009},
  keywords = {Methodology,Research Methodology,Social sciences},
  annotation = {OCLC: ocn212893577},
  file = {/home/ral/Zotero/storage/R8WRFFDY/Bickman and Rog - 2009 - The SAGE handbook of applied social research metho.pdf}
}

@book{bradburn_etal04,
  title = {Asking Questions: The Definitive Guide to Questionnaire Design - for Market Research, Political Polls, and Social and Health Questionnaires},
  shorttitle = {Asking Questions},
  author = {Bradburn, Norman M. and Sudman, Seymour and Wansink, Brian},
  year = {2004},
  edition = {Rev. ed},
  publisher = {Jossey-Bass},
  address = {San Francisco, Calif},
  isbn = {978-0-7879-7088-8},
  langid = {english},
  file = {/home/ral/Zotero/storage/3IZ7JYQ8/N M Bradburn Et Al Asking Questions The De - Unknown.pdf}
}

@book{dillman_etal14,
  title = {Internet, {{Phone}}, {{Mail}}, and {{Mixed}}-{{Mode Surveys}}: {{The Tailored Design Method}}},
  shorttitle = {Internet, {{Phone}}, {{Mail}}, and {{Mixed}}-{{Mode Surveys}}},
  author = {Dillman, Don A and Smyth, Jolene D and Christian, Leah Melani},
  year = {2014},
  month = aug,
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9781394260645},
  urldate = {2024-06-01},
  isbn = {978-1-394-26064-5},
  langid = {english},
  file = {/home/ral/Zotero/storage/GFY5Y8M9/Dillman et al. - 2014 - Internet, Phone, Mail, and Mixed‚ÄêMode Surveys The.pdf}
}

@book{fowler14,
  title = {Survey Research Methods},
  author = {Fowler, Floyd J.},
  year = {2014},
  series = {Applied Social Research Methods Series},
  edition = {Fifth edition},
  publisher = {SAGE},
  address = {Los Angeles},
  isbn = {978-1-4522-5900-0 978-1-4833-1240-8},
  langid = {english},
  lccn = {HN29 .F68 2014},
  keywords = {Social surveys},
  file = {/home/ral/Zotero/storage/FDJ8Z26T/Fowler - 2014 - Survey research methods.pdf}
}

@misc{gruber_weber24,
  title = {Rollama: {{An R}} Package for Using Generative Large Language Models through {{Ollama}}},
  shorttitle = {Rollama},
  author = {Gruber, Johannes B. and Weber, Maximilian},
  year = {2024},
  month = apr,
  number = {arXiv:2404.07654},
  eprint = {2404.07654},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-01},
  abstract = {rollama is an R package that wraps the Ollama API, which allows you to run different Generative Large Language Models (GLLM) locally. The package and learning material focus on making it easy to use Ollama for annotating textual or imagine data with open-source models as well as use these models for document embedding. But users can use or extend rollama to do essentially anything else that is possible through OpenAI's API, yet more private, reproducible and for free.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/ral/Zotero/storage/HM4JSXJH/Gruber and Weber - 2024 - rollama An R package for using generative large l.pdf}
}

@misc{jiang_etal23,
  title = {Mistral {{7B}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and Lavaud, L{\'e}lio Renard and Lachaux, Marie-Anne and Stock, Pierre and Scao, Teven Le and Lavril, Thibaut and Wang, Thomas and Lacroix, Timoth{\'e}e and Sayed, William El},
  year = {2023},
  month = oct,
  number = {arXiv:2310.06825},
  eprint = {2310.06825},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.06825},
  urldate = {2024-06-04},
  abstract = {We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/C6G277ZT/Jiang et al_2023_Mistral 7B.pdf;/home/ral/Zotero/storage/KT9ICMPL/2310.html}
}

@article{joshi_etal15,
  title = {Likert {{Scale}}: {{Explored}} and {{Explained}}},
  shorttitle = {Likert {{Scale}}},
  author = {Joshi, Ankur and Kale, Saket and Chandel, Satish and Pal, D.},
  year = {2015},
  month = jan,
  journal = {British Journal of Applied Science \& Technology},
  volume = {7},
  number = {4},
  pages = {396--403},
  issn = {22310843},
  doi = {10.9734/BJAST/2015/14975},
  urldate = {2024-06-01},
  abstract = {Likert scale is applied as one of the most fundamental and frequently used psychometric tools in educational and social sciences research. Simultaneously, it is also subjected to a lot of debates and controversies in regards with the analysis and inclusion of points on the scale. With this context, through reviewing the available literature and then clubbing the received information with coherent scientific thinking, this paper attempts to gradually build a construct around Likert scale. This analytical review begins with the necessity of psychometric tools like Likert scale andits variants and focuses on some convoluted issues like validity, reliability and analysis of the scale.},
  langid = {english},
  file = {/home/ral/Zotero/storage/T2CIRCMG/Joshi et al. - 2015 - Likert Scale Explored and Explained.pdf}
}

@book{likert32,
  title = {A Technique for the Measurement of Attitudes},
  author = {Likert, R.},
  year = {1932},
  series = {A Technique for the Measurement of Attitudes},
  number = {nos. 136-165},
  publisher = {Archives of Psychology},
  lccn = {33012634},
  file = {/home/ral/Zotero/storage/HQKV2UCI/Likert_1932.pdf}
}

@misc{meta24,
  title = {Introducing {{Meta Llama}} 3: {{The}} Most Capable Openly Available {{LLM}} to Date},
  shorttitle = {Introducing {{Meta Llama}} 3},
  author = {{Meta}},
  year = {2024},
  journal = {Meta AI},
  urldate = {2024-06-05},
  abstract = {Today, we're introducing Meta Llama 3, the next generation of our state-of-the-art open source large language model. In the coming months, we expect to share new capabilities, additional model sizes, and more.},
  howpublished = {https://ai.meta.com/blog/meta-llama-3/},
  langid = {english}
}

@misc{ollama24,
  title = {Ollama/Ollama},
  author = {{Ollama}},
  year = {2024},
  month = jun,
  urldate = {2024-06-02},
  abstract = {Get up and running with Llama 3, Mistral, Gemma, and other large language models.},
  copyright = {MIT},
  howpublished = {Ollama},
  keywords = {gemma,go,golang,llama,llama2,llama3,llava,llm,llms,mistral,ollama,phi3}
}

@techreport{openai23b,
  title = {{{GPT-4 Technical Report}}},
  author = {{OpenAI}},
  year = {2023},
  pages = {100},
  institution = {OpenAI},
  urldate = {2024-06-05},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer- based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  file = {/home/ral/Zotero/storage/9MGLMHI6/gpt-4.pdf}
}

@inproceedings{sevenans_etal14,
  title = {The {{Automated Coding}} of {{Policy Agendas}}: {{A Dictionary Based Approach}}},
  shorttitle = {The {{Automated Coding}} of {{Policy Agendas}}},
  author = {Sevenans, Julie and Albaugh, Quinn and Shahaf, Tal and Soroka, Stuart and Walgrave, Stefaan},
  year = {2014},
  month = jun,
  abstract = {For the coding of political and media texts, the Policy Agendas community has mostly taken a human coding approach, or they have turned to automated machine learning methods. Last year, we proposed an alternative dictionary-based approach for the automated content analysis of texts (see Albaugh et al. 2013). We designed a first version of an English and a Dutch CAP-dictionary, and we validated the results of the codings against human coded documents. Although the results were not perfect yet -- with respect to certain topic codes our dictionaries could certainly be improved -- we showed that dictionaries may produce reliable, valid and comparable measures of policy and media agendas. This year, we take the next step by doing three things. First, we further develop the Dutch and English dictionaries and try to replicate human coding results by making the dictionary assign single topic codes to single items. Second, we compare the dictionaries not only with human coded texts; we also validate them in a substantive manner. We expect individual Members of Parliament (MPs) to act most upon issues that they prioritize. Concretely, we test this by comparing MPs' dictionary-coded attention for issues with their committee membership. Third, we show that valuable insights can be gained from using the dictionaries in practice.},
  file = {/home/ral/Zotero/storage/BFCUW5ZS/Sevenans et al_2014_The Automated Coding of Policy Agendas.pdf}
}

@misc{yadav_bethard19,
  title = {A {{Survey}} on {{Recent Advances}} in {{Named Entity Recognition}} from {{Deep Learning}} Models},
  author = {Yadav, Vikas and Bethard, Steven},
  year = {2019},
  month = oct,
  number = {arXiv:1910.11470},
  eprint = {1910.11470},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-05},
  abstract = {Named Entity Recognition (NER) is a key component in NLP systems for question answering, information retrieval, relation extraction, etc. NER systems have been studied and developed widely for decades, but accurate systems using deep neural networks (NN) have only been introduced in the last few years. We present a comprehensive survey of deep neural network architectures for NER, and contrast them with previous approaches to NER based on feature engineering and other supervised or semi-supervised learning algorithms. Our results highlight the improvements achieved by neural networks, and show how incorporating some of the lessons learned from past work on feature-based NER systems can yield further improvements.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ral/Zotero/storage/2VKWYK38/Yadav_Bethard_2019_A Survey on Recent Advances in Named Entity Recognition from Deep Learning.pdf}
}
